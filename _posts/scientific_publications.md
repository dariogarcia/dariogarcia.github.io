---
layout: archive
title: "Scientific Publications"
permalink: /scientific_publications/
author_profile: false
---

### Scientific Issues:

A significant part of today's sciencific research (certainly the one originating at public institutions) is driven by the need to publish. The value of a researcher is basically determined by the yearly number of scientific papers written, by the reputation of the journals or conferences where those papers are published, and by the number of researchers that cite those publications in their own work. The first two factors say nothing of the quality or impact of a researcher's contribution. The first values quantity over quality, and the second rewards elitism. The third is at least a measure of scientific relevance, but not of scientific quality.

This far from perfect ecosystem where research has to grow and mature, has resulted in severe problems for science. Next we outline some of those. 

- Opaque Evaluation: Current evaluations (i.e., journal/conference reviews) are not published, and the people evaluating is not accountable for the quality of their reviews. This may lead to subjective reviews, which in turn result in unfair publication decisions. At the same time, readers of published papers are unaware of the issues the evaluators found on those, and have a harder time at identifying the limitations of published research.

- Unsuited Evaluation: Current evaluation (i.e., journal/conference reviews) is made by two to four volunteers who may not be experts on the topic. These reviewers are forced to decide on the publication of a scientific contribution without being fully aware of the state-of-the-art or its overall context.

- Unrewarded Evaluation: While having one of the more complicated and relevant roles in the scientific publication cycle, good reviewers (e.g., thorough, detailed, well-argued) are not rewarded. Additionally, posterior readers will not be able to benefit from their work due to opaque evaluation. Nonetheless, the first step in any scientific career is, or should be, reading and criticisizing lots of papers to properly understand the current state-of-the-art. 

- Lack of Replicability: Replicability is not a must for most publications, and papers which try to replicate other's work are not favored for publication. However, replicability is an essential part of consistent research.

- Urge for Publication and Abandoned Research: Scientists are forced to publish several papers per year, regardless of their actual relevance. Research is forced to produce results in the short term, abandoning the topic for a new one once the paper is accepted. This also results in limited scientific impact on society.

- Scientific Paper Visibility is Unscientific: Papers visibility is directly affected by the impact factor of the journal or conference where it is published. Popular papers appear higher on search engines which results in a rich get richer process that impoverishes science. Journal/Conference impact factors suposedly determine their relevance, and consequently the visibility of published papers. However, impact factors are not a well defined score, and are linked to a given journal/conference, not to the papers themselves. As such, it is useless for evaluating paper quality. At the same time, impact factors are used by institutions to evaluate the contributions of researchers. This leads researchers to pursue publications of those venues instead of producing quality research.


### Solutions

- Transparent Evaluation: Evaluation of papers should be an open and continuous process. Readers should be aware of the criticisms, and the level of reliability of the critics. Although unsigned reviews should be possible, to foster criticism in all contexts, those should be limited. Reviews should be reviewed, and reviewers should be accountable for their input.

- Idoneous Evaluation: For every research contribution there is a community, large or small, with the most knowledge on the topic. That is the community of researchers also working on the same area. These researchers will typically read and criticise the papers in their field when working on their own research and analyzing the state-of-the-art. Since the read and review process is already being done, all that is needed is to encourage the publication of the resulting comments. These experts on the topic are the best possible reviewers of a work, as they are truly interested in understanding every aspect of their related work. Authors should be encouraged to propose reviewers avoiding conflicts of interests, as relevant reviews leads to visibility.

- Recognized Reviewers: Good reviews are hard work, but their benefits are huge for science. Good reviewers (e.g., thorough, detailed, well-argued) should be acknowledged by the community, and should get proper recognition.

- Replicability by Default: Contributions which cannot be replicated have no relevance. Authors should be encouraged to facilitate the replicability of their work. Contributions replicating the work of others should also get proper recognition. The importance and visibility of papers should be directly related with replicability.

- Perpetual evaluation: Research should be continuously under review. As a result of other people's contributions, research should be improved and extended. Authors should be encouraged to take into account and apply comments made by the community. This would result in more complete contributions which remain relevant for longer periods.

- Objective Paper Visibility: Paper visibility should be based on many different aspects. Overall evaluation, citations, replicability, experience and reliability of reviewers and flags, are all relevant factors. Researchers should decide which combination of these factors is most relevant for them, and get access to publications according to their own requirements.

### Actors Involved

Let's summarize the rights and obligations of the actors that compose a scientific publication platform.

#### Authors

- Authors should not be allowed to submit an arbitrary number of original contributions per year.

- The number of original contributions an author may make should be related with the number of enhancing contributions that researcher makes on other people's original work. Enhancing contributions may be reviews, replicating other people's work, summarizing other papers or meta-reviewing. Clearly, a researcher who makes numerous and relevant enhancing contribution is in a better possition to perform more and better original contributions.  

- Authors should be encouraged to evaluate and take into account the enhancing contributions on their work, and to use them to improve their own original research. Updated versions of original contributions should be released ocasionally to meet the standards required by the scientific community and address their concerns.

#### Original Contributions

- Original contributions should recieve a minimum amount of reviews from recognized reviewers before getting the status of promising research.

- Promising research can only become well-stablished research after being replicated.

- Original research should be subject to red flags for fraud and plagiarism.

- Long-term relevance of original contributions should be based mainly on citations.

- One may only cite contributions



## References

[Kriegeskorte, Nikolaus, Alexander Walther, and Diana Deca. "An emerging consensus for open evaluation: 18 visions for the future of scientific publishing." Frontiers in computational neuroscience 6 (2012).](http://journal.frontiersin.org/article/10.3389/fncom.2012.00094/full)
