---
layout: post
title: A new Platform for Science & Research
date: 2021-12-14 00:00:00 +0300
description: The process by which research gets published is severely flawed. The whole system is based on old principles, and obsolete in the face of new technology. We identify those problems, their solutions, and propose a new platform for science to organize it.
img: research.jpg 
tags: [Science, Research, Organization]
---

Next, we propose a new structure for scientific reviewing, publication and dissemination. To do so, we first identify the main problems in how research works today.

### Scientific Issues:

A significant part of today's sciencific research (particularly the one originating at public institutions) is driven by the need to publish. The value of a researcher is determined by the yearly number of scientific papers written, by the reputation of the journals or conferences where those papers are published, and by the number of researchers that reference (i.e., cite) those publications in their own work. The first factor values quantity, not quality. The second rewards elitism, and puts lotsof power on the hands of a few editors. The third is a measure of scientific relevance, but not of scientific quality. This far from perfect ecosystem has caused systemic problems in science. Such as:

* Opaque Evaluation: Current paper evaluations (i.e., journal/conference reviews) are rarely published, removing all responsability and accountability from anonymous reviewers. This may lead to subjective, or plain arbitrary reviews, which in turn result in unfair decisions. Once a paper is published, readers are unaware of the issues found by evaluators, and have a harder time at identifying the limitations of published research.

* Unsuited Evaluation: Current evaluation is made by a few volunteers who may not be experts on the topic. These reviewers are forced to decide on the value of some piece of research without being fully aware of the state-of-the-art or its overall context.

* Unrewarded Evaluation: While having one of the most complicated and relevant roles in the scientific cycle, good reviewers (e.g., thorough, detailed, well-argued) are not rewarded. Additionally, posterior readers will not be able to benefit from their work due to opaque evaluation. Nonetheless, the first step in any scientific career is, or should be, reading and criticisizing lots of papers to properly understand the current state-of-the-art, as well as the contents and structure of a good paper.

* Lack of Replicability: Replicability is not a must for most publications, and papers which try to replicate other's work are not favored for publication. However, replicability is an essential part of consistent research, and should be actively encouraged.

* Urge for Publication and Abandoned Research: Scientists are forced to publish several papers per year, regardless of their actual relevance. This favours short lived research and the abandonement of challenging topics. The lack of consistent research makes it harder for science to reach the general public.

* Scientific Paper Visibility is Unscientific: Papers visibility is directly affected by the impact factor of the journal or conference where it is published. Popular papers appear higher on search engines which results in a rich get richer process that impoverishes science. Journal/Conference impact factors suposedly determine their relevance, and consequently the visibility of published papers. However, impact factors are not a well defined score, and are linked to a given journal/conference, not to the papers themselves. As such, it is useless for evaluating paper quality. At the same time, impact factors are used by institutions to evaluate the contributions of researchers. This leads researchers to pursue publications of those venues instead of producing quality research.

* Scientific Authorship & Contribution: Papers today may have from one author, to dozens of them. This dillutes the relevance of each researcher with regards to their own work, and complicates the task of attribution. It is often the case that one or more authors have not read the paper they sign, owning the right to authorship by rank or reputation.

* Limited State-of-the-art: Researchers are responsible for contextualizing their work on previous research, understanding the context and implications of their work. As the number of research works grows, it quickly becomes unfeasible to find, read and integrate every related work. 

Ok, so these are the problem. Seem like a lot. Let's see if we can find a few solutions.

### Solutions

* Transparent Evaluation: Evaluation of papers should be an open and continuous process. Readers should be aware of the criticisms, as well as the expertisee of critics. Unsigned reviews should remain a possibility to foster free criticism, but that ought not to be the only way. Reviews should be reviewed, and reviewers should be accountable for their input.

* Idoneous Evaluation: For every research contribution there is a community, large or small, with the most knowledge on the topic. That is the community of researchers also working on the same area. These researchers will typically read and assess the relevance of papers in their field when working on their own research. This means the reading effort is already being done by the experts in the field, just not publicly. These experts on the topic are the best possible reviewers of a work, as they are selfishly interested in understanding every aspect of their related work.


* Recognized Reviewers: Writing good reviews takes time and effort, but their benefits are huge for science. Good reviewers (e.g., thorough, detailed, well-argued) should be acknowledged by the community, and should get proper recognition and reward.

* Replicability by Default: Contributions which cannot be replicated are of no relevance. Authors should be encouraged to facilitate the replicability of their work. Contributions replicating the work of others should also get proper recognition. The importance and visibility of papers should be directly related to their replicability.

* Perpetual evaluation: Research should be continuously under review. As a result of other people's contributions, research should be improved and extended. Authors should be encouraged to take into account and apply comments or findings made by the community. This would result in more complete contributions which would remain relevant for longer periods.

* Objective Paper Visibility: Paper visibility should be based on aspects like overall evaluation, citations, replicability, continued interest, and others. Research should be sortable by any combination of these factors.

* Explicit Author Contribution: Papers should have a limited set of contribution types. For example, original concept (the happy idea needed in many steps of the research project), design & refinement (the continuous planning and reconsideration of research) and implementation (conducting experiments, transforming ideas into reality).

* State-of-the-art Expansion: The creation of the state-of-the-art part of a paper could be done collaboratively. Authors of other works, or conocieurs of other research papers could enhance a new paper by contextualizing it beyond their original authors knowledge. This would provide a much richer background to papers, as well as identify potential side-effects, applications and flaws of a research contribution.

### A New Platform for Research

The previously proposed solution cannot be applied under today's regime of publishers and venues. To organize all proposed solutions, we need to create a platform that includes all relevant actors. 

#### Authors

* Authors should not be allowed to submit an arbitrary number of original contributions per year. The amount of quality research a person can do in a year is limited. 

* The number of original contributions an author may make should be related with the number of enhancing contributions that researcher makes on other people's original work. Enhancing contributions may be reviews, replicating other people's work, summarizing other papers or meta-reviewing. Clearly, a researcher who makes numerous and relevant enhancing contribution is in a better possition to perform more and better original contributions.

* Authors should be encouraged to evaluate and take into account the enhancing contributions on their work, using it to improve their own research. Updated versions of original contributions should be released ocasionally to meet the standards required by the scientific community and address concerns of special interest.

#### Original Research Contributions

* Original contributions should recieve a minimum amount of reviews from recognized reviewers before getting the status of reliable research.

* Reliable research can only become stablished science after being replicated.

* Each original contribution has a clear set of authors, each with a clear contribution. All impact derived from an original contribution is equally split among authors based on their role.

#### Enhancing Research Contributions

Beyond original research, a researcher can contribute significantly to science. This includes:

* Reviews
* Meta-reviews
* State-of-the-art expansion
* Replication of original research
* Summarization and dissemination of research

Each of these contributions should be associated with the researcher doing it. Although anonymity is optional, this would be unveiled if a red flag is raised on their work (e.g., prevaricating reviews, false replication report, plagiarism in reviews/summaries/dissemination produced)

### References

[Kriegeskorte, Nikolaus, Alexander Walther, and Diana Deca. "An emerging consensus for open evaluation: 18 visions for the future of scientific publishing." Frontiers in computational neuroscience 6 (2012).](http://journal.frontiersin.org/article/10.3389/fncom.2012.00094/full)
