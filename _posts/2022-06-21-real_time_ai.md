---
layout: post
title: NoCReAS - No to Concealed Real-time AI Support
date: 2022-06-21 00:00:00 +0300
description: An initiative for the regulation of real-time AI language models, to restrict their use on human-human interactions.
img: face_pexels-mohamed-abdelghaffar-771742.jpg 
tags: [Artificial Intelligence, Neural Network, Science]
---

I hereby propose the initiative "No to Concealed Real-time AI Support" or NoCReAS for kinda-short. And what is that you ask? Well, it's an incoming application of AI that will affect all of your social interactions. Sounds promising, right?

Let's start with AI language models. Huge libraries of word and text properties, extracted from all sort of digital sources. These models generate indistinguishable text in any conversational situation TODAY. Soon they will provide better responses than us in certain domains.

Language models will probably be regulated like deep fakes in the AI Act. That is, notifying users when interacting with content generated by an AI, to avoid impersonation or deception. That will work for digital interactions, most likely though annoying consent forms (yay!).

But it won't stop there, cause there's a loophole. You can provide real-time AI language support to a consenting person, that's well and all. But what if this person uses it to impersonate or deceive someone? That is, what if someone uses "concealed real-time AI support"?

Phones, watches, glasses, earphones, any other gadget. We are integrating our digital devices as an extension of us, and this will only grows stronger. At some point we will be able to percieve AI suggestions unknowingly to others. Concealed real-time AI support is unavoidable.

At first, you will constantly wonder who are you talking with. Was it her or an AI who made that joke? Eventually, you will not trust your interlocutors, their intent and sentiment. Open and fair conversations will be gone. Only unfaithful, dubious interactions will remain.

EU regulation says, "people has the right to know if they are talking to an AI". We say, "people has the right to know if they are talking to an AI ~through person~".

In the case of deep fakes, regulation had a late start and is struggling to catch up. For real-time human interactions let's fix it before it's broken. Cause it will be broken soon enough, and the damage to our society can be huge.
